<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="avatar.jpg"/><link rel="stylesheet" href="_next/static/css/54e43c5c623f2a4b.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="_next/static/chunks/webpack-f24413172d2dbc89.js"/><script src="_next/static/chunks/4bd1b696-1897831b3bbea01c.js" async=""></script><script src="_next/static/chunks/684-d5e386b02d389e2f.js" async=""></script><script src="_next/static/chunks/main-app-ae42cce3f114182a.js" async=""></script><script src="_next/static/chunks/766-235bf725b637b196.js" async=""></script><script src="_next/static/chunks/874-d2167264e87190e5.js" async=""></script><script src="_next/static/chunks/app/page-4b888e98a52f9144.js" async=""></script><title>Tongyuan Bai - Academic Portfolio</title><meta name="description" content="AI researcher specializing in 3D scene generation, video generation, and diffusion models. Sharing latest research achievements and academic insights."/><meta name="author" content="Tongyuan Bai"/><meta name="keywords" content="artificial intelligence,machine learning,deep learning,3D scene generation,diffusion models,computer vision"/><meta name="creator" content="Tongyuan Bai"/><meta name="publisher" content="Tongyuan Bai"/><meta name="robots" content="index, follow"/><meta property="og:title" content="Tongyuan Bai - Academic Portfolio"/><meta property="og:description" content="AI researcher specializing in 3D scene generation, video generation, and diffusion models."/><meta property="og:url" content="https://cangmushui.github.io/"/><meta property="og:site_name" content="Tongyuan Bai&#x27;s Academic Portfolio"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://cangmushui.github.io/avatar.jpg"/><meta property="og:image:width" content="400"/><meta property="og:image:height" content="400"/><meta property="og:image:alt" content="Tongyuan Bai"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@cangmushui"/><meta name="twitter:title" content="Tongyuan Bai - Academic Portfolio"/><meta name="twitter:description" content="AI researcher specializing in 3D scene generation and diffusion models"/><meta name="twitter:image" content="https://cangmushui.github.io/avatar.jpg"/><link rel="icon" href="favicon.ico" type="image/x-icon" sizes="16x16"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="font-serif antialiased"><div class="min-h-screen bg-white dark:bg-gray-900"><header class="
        fixed top-0 left-0 right-0 z-50 transition-all duration-300
        bg-white/20 dark:bg-gray-900/20 backdrop-blur-sm border-b border-white/5 dark:border-gray-700/10
      "><nav class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><div class="flex-shrink-0"><a class="text-xl font-bold transition-colors text-white drop-shadow-lg hover:text-blue-400 dark:hover:text-blue-400" href="#home">Tongyuan Bai</a></div><div class="hidden md:block"><div class="ml-10 flex items-baseline space-x-6"><button class="px-4 py-2 rounded-md text-xl font-semibold transition-all tracking-wide text-white drop-shadow-lg hover:bg-white/10 hover:text-blue-400 dark:hover:text-blue-400">Home</button><button class="px-4 py-2 rounded-md text-xl font-semibold transition-all tracking-wide text-white drop-shadow-lg hover:bg-white/10 hover:text-blue-400 dark:hover:text-blue-400">About</button><button class="px-4 py-2 rounded-md text-xl font-semibold transition-all tracking-wide text-white drop-shadow-lg hover:bg-white/10 hover:text-blue-400 dark:hover:text-blue-400">Publications</button><button class="px-4 py-2 rounded-md text-xl font-semibold transition-all tracking-wide text-white drop-shadow-lg hover:bg-white/10 hover:text-blue-400 dark:hover:text-blue-400">News</button></div></div><div class="md:hidden"><button class="p-2 rounded-md transition-colors text-white drop-shadow-lg hover:bg-white/10 hover:text-blue-400 dark:hover:text-blue-400"><svg class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></nav></header><main><section id="home" class="min-h-screen flex items-center justify-center relative overflow-hidden"><div class="absolute inset-0 bg-gradient-to-br from-blue-50 to-indigo-100 dark:from-gray-900 dark:to-gray-800"></div><div class="absolute inset-0 transition-all duration-2000 ease-out bg-gradient-to-br from-blue-50/30 via-indigo-50/20 to-purple-50/10 opacity-60"></div><div class="absolute inset-0 transition-all duration-1500 ease-out opacity-100"><div class="absolute inset-0 bg-gradient-to-br from-blue-100/70 to-indigo-200/70 dark:from-blue-900/70 dark:to-indigo-900/70"></div><div class="absolute bottom-12 left-1/2 transform -translate-x-1/2 text-center"><div class="w-40 h-1 bg-white/20 rounded-full overflow-hidden mb-3"><div class="h-full bg-gradient-to-r from-blue-400 to-indigo-400 transition-all duration-300 ease-out rounded-full" style="width:0%"></div></div><p class="text-sm text-white/80 font-light">Loading beautiful scenery...</p></div></div><div class="absolute inset-0 transition-all duration-2000 ease-out opacity-0"></div><div class="relative z-10 max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-20"><div class="grid grid-cols-1 lg:grid-cols-2 gap-12 items-center"><div class="text-center lg:text-left"><div class="relative inline-block"><div class="absolute -inset-6 rounded-full transition-all duration-2000 ease-out bg-gradient-to-r from-blue-500/20 via-indigo-500/20 to-purple-500/20 blur-xl"></div><div class="absolute -inset-3 rounded-full border-2 transition-all duration-2000 ease-out border-blue-300/40 bg-blue-50/20 dark:border-blue-600/40 dark:bg-blue-900/20 backdrop-blur-sm"></div><div class="w-64 h-64 sm:w-80 sm:h-80 relative mx-auto lg:mx-0 rounded-full overflow-hidden transition-all duration-2000 ease-out ring-4 ring-blue-200/50 shadow-xl shadow-blue-500/20 dark:ring-blue-600/50 dark:shadow-blue-900/30"><img alt="Tongyuan Bai" decoding="async" data-nimg="fill" class="object-cover transition-all duration-2000 ease-out brightness-100 contrast-100" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="avatar.jpg"/><div class="absolute inset-0 transition-all duration-2000 ease-out bg-gradient-to-br from-blue-400/5 via-transparent to-indigo-500/5"></div></div><div class="absolute -inset-8 rounded-full transition-all duration-3000 ease-out bg-gradient-to-r from-blue-400/10 via-indigo-400/10 to-purple-400/10 opacity-40 blur-2xl animate-pulse"></div><div class="absolute -inset-10 pointer-events-none"><div class="absolute w-2 h-2 rounded-full transition-all duration-2000 ease-out bg-blue-400/60" style="left:20%;top:15%;animation-delay:0s;animation:float 3s ease-in-out infinite alternate"></div><div class="absolute w-2 h-2 rounded-full transition-all duration-2000 ease-out bg-blue-400/60" style="left:80%;top:55%;animation-delay:0.5s;animation:float 3.5s ease-in-out infinite alternate"></div><div class="absolute w-2 h-2 rounded-full transition-all duration-2000 ease-out bg-blue-400/60" style="left:60%;top:25%;animation-delay:1s;animation:float 4s ease-in-out infinite alternate"></div><div class="absolute w-2 h-2 rounded-full transition-all duration-2000 ease-out bg-blue-400/60" style="left:40%;top:65%;animation-delay:1.5s;animation:float 4.5s ease-in-out infinite alternate"></div><div class="absolute w-2 h-2 rounded-full transition-all duration-2000 ease-out bg-blue-400/60" style="left:20%;top:35%;animation-delay:2s;animation:float 5s ease-in-out infinite alternate"></div><div class="absolute w-2 h-2 rounded-full transition-all duration-2000 ease-out bg-blue-400/60" style="left:80%;top:75%;animation-delay:2.5s;animation:float 5.5s ease-in-out infinite alternate"></div></div></div></div><div class="text-center lg:text-left"><h1 class="text-3xl sm:text-4xl lg:text-4xl font-serif font-normal tracking-wide mb-8"><span class="bg-gradient-to-r transition-all duration-1000 from-gray-900 via-blue-800 to-indigo-900 dark:from-white dark:via-blue-300 dark:to-indigo-300 bg-clip-text text-transparent drop-shadow-lg">Tongyuan Bai</span></h1><div class="mb-6 space-y-2"><p class="text-xl font-serif font-light tracking-wide italic transition-all duration-1000 text-slate-700 dark:text-slate-300">Ph.D. Student</p><p class="text-lg font-serif font-light tracking-wider transition-all duration-1000 text-slate-600 dark:text-slate-400">ICL Group, School of Artificial Intelligence</p><p class="text-lg font-serif font-light tracking-wider transition-all duration-1000 text-slate-600 dark:text-slate-400">Jinlin university</p></div><div class="mb-8 max-w-2xl"><p class="text-lg font-serif font-light leading-relaxed tracking-wide text-justify p-6 border-2 border-dashed rounded-lg shadow-lg hover:shadow-xl transition-all duration-1000 text-slate-700 dark:text-slate-300 border-slate-300 dark:border-slate-600 bg-gradient-to-br from-slate-50/50 to-blue-50/30 dark:from-slate-800/50 dark:to-blue-900/30">I am a Ph.D. student working at the intersection of artificial intelligence and computer graphics. My current work focuses on generating 3D spatial layouts for indoor and outdoor scene using diffusion models and large language models. My research vision is to automate the creation of diverse 3D scene, particularly those that exist solely in the realm of human imagination, contributing to the development of richly immersive and limitless virtual worlds.</p></div><div class="flex flex-wrap justify-center lg:justify-start gap-4 mb-8"><a href="https://scholar.google.com/citations?user=NHBB0_4AAAAJ" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors"><svg class="w-5 h-5 mr-2" fill="currentColor" viewBox="0 0 24 24"><path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"></path></svg>Google Scholar</a><a href="https://github.com/cangmushui" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-4 py-2 bg-gray-800 text-white rounded-lg hover:bg-gray-900 transition-colors"><svg class="w-5 h-5 mr-2" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"></path></svg>GitHub</a><a href="https://linkedin.com/in/Ê∞¥-Êú®-680a48224" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 transition-colors"><svg class="w-5 h-5 mr-2" fill="currentColor" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg>LinkedIn</a></div><div class="space-y-1"><p class="text-sm font-serif font-light tracking-wider flex items-center justify-center lg:justify-start transition-all duration-1000 text-slate-600 dark:text-slate-400"><span class="mr-2">üìß</span>baity23@mails.jlu.edu.cn</p><p class="text-sm font-serif font-light tracking-wider flex items-center justify-center lg:justify-start transition-all duration-1000 text-slate-600 dark:text-slate-400"><span class="mr-2">üìç</span>Changchun, China</p></div></div></div><div class="absolute bottom-8 left-1/2 transform -translate-x-1/2 animate-bounce"><svg class="w-6 h-6 transition-all duration-1000 text-gray-600 dark:text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 14l-7 7m0 0l-7-7m7 7V3"></path></svg></div></div></section><section id="about" class="py-16 px-4 sm:px-6 lg:px-8 bg-gradient-to-br from-amber-50/60 via-yellow-50/40 to-orange-50/30 dark:from-amber-900/20 dark:via-yellow-900/15 dark:to-orange-900/10"><div class="max-w-4xl mx-auto"><div class="text-center mb-12"><h2 class="text-3xl font-bold text-gray-900 dark:text-white mb-4">About Me</h2><p class="text-lg text-gray-600 dark:text-gray-300">My background and expertise</p></div><div class="grid grid-cols-1 lg:grid-cols-3 gap-8"><div class="
        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 
        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20
        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 
        p-6
      "><div class="text-center mb-4"><div class="w-12 h-12 bg-blue-100 dark:bg-blue-900 rounded-lg flex items-center justify-center mx-auto mb-4"><svg class="w-6 h-6 text-blue-600 dark:text-blue-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path></svg></div><h3 class="text-xl font-semibold text-gray-900 dark:text-white mb-4">Research Interests</h3></div><div class="space-y-2"><div class="flex items-center"><div class="w-2 h-2 bg-blue-500 rounded-full mr-3"></div><span class="text-gray-700 dark:text-gray-300">3D Scene Generation</span></div><div class="flex items-center"><div class="w-2 h-2 bg-blue-500 rounded-full mr-3"></div><span class="text-gray-700 dark:text-gray-300">Computer Graphics</span></div><div class="flex items-center"><div class="w-2 h-2 bg-blue-500 rounded-full mr-3"></div><span class="text-gray-700 dark:text-gray-300">Diffusion Model</span></div><div class="flex items-center"><div class="w-2 h-2 bg-blue-500 rounded-full mr-3"></div><span class="text-gray-700 dark:text-gray-300">Large Language Model</span></div><div class="flex items-center"><div class="w-2 h-2 bg-blue-500 rounded-full mr-3"></div><span class="text-gray-700 dark:text-gray-300">Agent&amp;MCP</span></div><div class="flex items-center"><div class="w-2 h-2 bg-blue-500 rounded-full mr-3"></div><span class="text-gray-700 dark:text-gray-300">Reinforcement Learning</span></div><div class="flex items-center"><div class="w-2 h-2 bg-blue-500 rounded-full mr-3"></div><span class="text-gray-700 dark:text-gray-300">Any Technology that Helps Build Interesting Worlds</span></div></div></div><div class="
        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 
        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20
        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 
        p-6
      "><div class="text-center mb-4"><div class="w-12 h-12 bg-green-100 dark:bg-green-900 rounded-lg flex items-center justify-center mx-auto mb-4"><svg class="w-6 h-6 text-green-600 dark:text-green-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 14l9-5-9-5-9 5 9 5z"></path><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 14l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14z"></path><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 14l9-5-9-5-9 5 9 5zm0 0l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14z"></path></svg></div><h3 class="text-xl font-semibold text-gray-900 dark:text-white mb-4">Education</h3></div><div class="space-y-4"><div class="border-l-2 border-blue-200 dark:border-blue-700 pl-4"><div class="flex items-start space-x-3"><div class="flex-shrink-0 mt-1"><img alt="Tianjin University logo" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="w-8 h-8 object-contain rounded" style="color:transparent" src="logos/tju.svg"/></div><div class="flex-1"><h4 class="font-semibold text-gray-900 dark:text-white">Bachelor</h4><p class="text-sm text-gray-600 dark:text-gray-400">Automation</p><p class="text-sm font-medium text-blue-600 dark:text-blue-400">Tianjin University</p><p class="text-xs text-gray-500 dark:text-gray-500">graduated in 2018</p></div></div></div><div class="border-l-2 border-blue-200 dark:border-blue-700 pl-4"><div class="flex items-start space-x-3"><div class="flex-shrink-0 mt-1"><img alt="Dalian University of Technology logo" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="w-8 h-8 object-contain rounded" style="color:transparent" src="logos/dlut.svg"/></div><div class="flex-1"><h4 class="font-semibold text-gray-900 dark:text-white">Master</h4><p class="text-sm text-gray-600 dark:text-gray-400">Control Engineering</p><p class="text-sm font-medium text-blue-600 dark:text-blue-400">Dalian University of Technology</p><p class="text-xs text-gray-500 dark:text-gray-500">2020 - 2023</p></div></div></div><div class="border-l-2 border-blue-200 dark:border-blue-700 pl-4"><div class="flex items-start space-x-3"><div class="flex-shrink-0 mt-1"><img alt="Jilin University logo" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="w-8 h-8 object-contain rounded" style="color:transparent" src="logos/jlu.svg"/></div><div class="flex-1"><h4 class="font-semibold text-gray-900 dark:text-white">Ph.D. Candidate</h4><p class="text-sm text-gray-600 dark:text-gray-400">Artificial Intelligence</p><p class="text-sm font-medium text-blue-600 dark:text-blue-400">Jilin University</p><p class="text-xs text-gray-500 dark:text-gray-500">2023 - Present</p></div></div></div></div></div><div class="
        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 
        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20
        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 
        p-6
      "><div class="text-center mb-4"><div class="w-12 h-12 bg-purple-100 dark:bg-purple-900 rounded-lg flex items-center justify-center mx-auto mb-4"><svg class="w-6 h-6 text-purple-600 dark:text-purple-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 13.255A23.931 23.931 0 0112 15c-3.183 0-6.22-.62-9-1.745M16 6V4a2 2 0 00-2-2h-4a2 2 0 00-2-2v2m8 0V6a2 2 0 012 2v6a2 2 0 01-2 2H6a2 2 0 01-2-2V8a2 2 0 012-2V6m8 0H8m0 0h-.01M8 6h.01M8 10h.01M8 10h.01M8 14h.01M8 14h.01"></path></svg></div><h3 class="text-xl font-semibold text-gray-900 dark:text-white mb-4">Work Experience</h3></div><div class="space-y-4"><div class="border-l-2 border-purple-200 dark:border-purple-700 pl-4"><h4 class="font-semibold text-gray-900 dark:text-white">FPGA Radar Engineer</h4><p class="text-sm text-gray-600 dark:text-gray-400">Worked on FPGA-based radar systems development and signal processing.</p><p class="text-sm font-medium text-purple-600 dark:text-purple-400">Leijiu Technology Co., Ltd.</p><p class="text-xs text-gray-500 dark:text-gray-500">2018 - 2019</p></div><div class="border-l-2 border-purple-200 dark:border-purple-700 pl-4"><h4 class="font-semibold text-gray-900 dark:text-white">Backend Engineer(Intern)</h4><p class="text-sm text-gray-600 dark:text-gray-400">Worked as a backend engineer intern in the Overseas Recommendation System team, responsible for backend development.</p><p class="text-sm font-medium text-purple-600 dark:text-purple-400">ByteDance-Data-AML</p><p class="text-xs text-gray-500 dark:text-gray-500">2022.6 - 2022.9</p></div></div></div></div></div></section><section id="publications" class="py-16 px-4 sm:px-6 lg:px-8 bg-gradient-to-br from-amber-50/50 via-yellow-50/30 to-orange-50/20 dark:from-amber-900/15 dark:via-yellow-900/10 dark:to-orange-900/5"><div class="max-w-4xl mx-auto"><div class="text-center mb-12"><h2 class="text-3xl font-bold text-gray-900 dark:text-white mb-4">Publications</h2><p class="text-lg text-gray-600 dark:text-gray-300">My research contributions and academic publications</p></div><div class="flex justify-center mb-8"><div class="bg-gray-100 dark:bg-gray-700 rounded-lg p-1"><button class="px-4 py-2 rounded-md text-sm font-medium transition-colors bg-white dark:bg-gray-600 text-gray-900 dark:text-white shadow">All Papers</button><button class="px-4 py-2 rounded-md text-sm font-medium transition-colors text-gray-600 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white">Featured Papers</button></div></div><div class="space-y-8"><div class="
        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 
        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20
        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 
        overflow-hidden
      "><div class="flex flex-col md:flex-row"><div class="w-full md:w-1/3 flex-shrink-0"><div class="relative h-48 sm:h-56 md:h-full p-4 flex items-center justify-center bg-gray-50 dark:bg-gray-800"><div class="relative w-full max-w-sm h-40 sm:h-48 md:w-84 md:h-60"><img alt="FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts" loading="lazy" decoding="async" data-nimg="fill" class="object-contain rounded" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="publications/cvpr25bai.png"/></div></div></div><div class="w-full md:w-2/3 p-4 md:p-6"><div class="flex flex-col sm:flex-row sm:items-start sm:justify-between mb-4"><div class="flex-1 mb-2 sm:mb-0"><h3 class="text-lg sm:text-xl font-bold text-gray-900 dark:text-white mb-2">FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts</h3><div class="flex items-center gap-2 mb-2 flex-wrap"><p class="text-sm sm:text-base text-gray-600 dark:text-gray-400 whitespace-nowrap"><em>CVPR 2025</em></p><span class="px-2 py-0.5 rounded text-xs font-medium bg-purple-100 text-purple-700 dark:bg-purple-900 dark:text-purple-200">CCFA</span><span class="px-2 py-0.5 rounded text-xs font-medium bg-gray-50 text-gray-500 dark:bg-gray-800/30 dark:text-gray-400">Conference</span><span class="text-sm text-green-600 dark:text-green-400 font-medium">accepted</span></div><p class="text-sm sm:text-base text-gray-700 dark:text-gray-300 mb-2"><span>Tongyuan Bai<!-- -->, </span><span>Wangyuanfan Bai<!-- -->, </span><span>Dong Chen<!-- -->, </span><span>Tieru Wu<!-- -->, </span><span>Manyi Li<!-- -->, </span><span>Rui Ma</span></p></div></div><p class="text-sm sm:text-base text-gray-700 dark:text-gray-300 mb-4 line-clamp-3">Controllability plays a crucial role in the practical applications of 3D indoor scene synthesis. Existing works either allow rough language-based control, that is convenient but lacks fine-grained scene customization, or employ graph based control, which offers better controllability but demands considerable knowledge for the cumbersome graph design process. To address these challenges, we present FreeScene, a user-friendly framework that enables both convenient and effective control for indoor scene this http URL, FreeScene supports free-form user inputs including text description and/or reference images, allowing users to express versatile design intentions. The user inputs are adequately analyzed and integrated into a graph representation by a VLM-based Graph Designer. We then propose MG-DiT, a Mixed Graph Diffusion Transformer, which performs graph-aware denoising to enhance scene generation. Our MG-DiT not only excels at preserving graph structure but also offers broad applicability to various tasks, including, but not limited to, text-to-scene, graph-to-scene, and rearrangement, all within a single model. Extensive experiments demonstrate that FreeScene provides an efficient and user-friendly solution that unifies text-based and graph based scene synthesis, outperforming state-of-the-art methods in terms of both generation quality and controllability in a range of applications.</p><div class="flex flex-wrap gap-2 sm:gap-3"><a href="https://arxiv.org/pdf/2506.02781" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 bg-blue-600 text-white rounded-md hover:bg-blue-700 transition-colors text-sm"><svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 10v6m0 0l-3-3m3 3l3-3m2 8H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg>Paper</a><a href="https://cangmushui.github.io/FreeScene-io/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 bg-green-600 text-white rounded-md hover:bg-green-700 transition-colors text-sm"><svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 12a9 9 0 01-9 9m9-9a9 9 0 00-9-9m9 9H3m9 9v-9m0 9c-1.657 0-3-4.03-3-9s1.343-9 3-9m0 18c1.657 0 3-4.03 3-9s-1.343-9-3-9m-9 9l9-9"></path></svg>Project</a><a href="https://github.com/cangmushui/FreeScene" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 bg-gray-800 text-white rounded-md hover:bg-gray-900 transition-colors text-sm"><svg class="w-4 h-4 mr-1" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"></path></svg>Code</a></div></div></div></div><div class="
        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 
        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20
        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 
        overflow-hidden
      "><div class="flex flex-col md:flex-row"><div class="w-full md:w-1/3 flex-shrink-0"><div class="relative h-48 sm:h-56 md:h-full p-4 flex items-center justify-center bg-gray-50 dark:bg-gray-800"><div class="relative w-full max-w-sm h-40 sm:h-48 md:w-84 md:h-60"><img alt="SigStyle: Signature Style Transfer via Personalized Text-to-Image Models" loading="lazy" decoding="async" data-nimg="fill" class="object-contain rounded" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="publications/aaai25wang.png"/></div></div></div><div class="w-full md:w-2/3 p-4 md:p-6"><div class="flex flex-col sm:flex-row sm:items-start sm:justify-between mb-4"><div class="flex-1 mb-2 sm:mb-0"><h3 class="text-lg sm:text-xl font-bold text-gray-900 dark:text-white mb-2">SigStyle: Signature Style Transfer via Personalized Text-to-Image Models</h3><div class="flex items-center gap-2 mb-2 flex-wrap"><p class="text-sm sm:text-base text-gray-600 dark:text-gray-400 whitespace-nowrap"><em>AAAI 2025</em></p><span class="px-2 py-0.5 rounded text-xs font-medium bg-purple-100 text-purple-700 dark:bg-purple-900 dark:text-purple-200">CCFA</span><span class="px-2 py-0.5 rounded text-xs font-medium bg-gray-50 text-gray-500 dark:bg-gray-800/30 dark:text-gray-400">Conference</span><span class="text-sm text-green-600 dark:text-green-400 font-medium">accepted</span></div><p class="text-sm sm:text-base text-gray-700 dark:text-gray-300 mb-2"><span>Ye Wang<!-- -->, </span><span>Tongyuan Bai<!-- -->, </span><span>Xuping Xie<!-- -->, </span><span>Zili Yi<!-- -->, </span><span>Yilin Wang<!-- -->, </span><span>Rui Ma</span></p></div></div><p class="text-sm sm:text-base text-gray-700 dark:text-gray-300 mb-4 line-clamp-3">Style transfer enables the seamless integration of artistic styles from a style image into a content image, resulting in visually striking and aesthetically enriched outputs. Despite numerous advances in this field, existing methods did not explicitly focus on the signature style, which represents the distinct and recognizable visual traits of the image such as geometric and structural patterns, color palettes and brush strokes etc. In this paper, we introduce SigStyle, a framework that leverages the semantic priors that embedded in a personalized text-to-image diffusion model to capture the signature style representation. This style capture process is powered by a hypernetwork that efficiently fine-tunes the diffusion model for any given single style image. Style transfer then is conceptualized as the reconstruction process of content image through learned style tokens from the personalized diffusion model. Additionally, to ensure the content consistency throughout the style transfer process, we introduce a time-aware attention swapping technique that incorporates content information from the original image into the early denoising steps of target image generation. Beyond enabling high-quality signature style transfer across a wide range of styles, SigStyle supports multiple interesting applications, such as local style transfer, texture transfer, style fusion and style-guided text-to-image generation. Quantitative and qualitative evaluations demonstrate our approach outperforms existing style transfer methods for recognizing and transferring the signature styles.</p><div class="flex flex-wrap gap-2 sm:gap-3"><a href="https://arxiv.org/pdf/2502.13997" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 bg-blue-600 text-white rounded-md hover:bg-blue-700 transition-colors text-sm"><svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 10v6m0 0l-3-3m3 3l3-3m2 8H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg>Paper</a><a href="https://sigstyle.github.io/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 bg-green-600 text-white rounded-md hover:bg-green-700 transition-colors text-sm"><svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 12a9 9 0 01-9 9m9-9a9 9 0 00-9-9m9 9H3m9 9v-9m0 9c-1.657 0-3-4.03-3-9s1.343-9 3-9m0 18c1.657 0 3-4.03 3-9s-1.343-9-3-9m-9 9l9-9"></path></svg>Project</a><a href="https://github.com/wangyePHD/SigStyle" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 bg-gray-800 text-white rounded-md hover:bg-gray-900 transition-colors text-sm"><svg class="w-4 h-4 mr-1" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"></path></svg>Code</a></div></div></div></div><div class="
        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 
        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20
        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 
        overflow-hidden
      "><div class="flex flex-col md:flex-row"><div class="w-full md:w-1/3 flex-shrink-0"><div class="relative h-48 sm:h-56 md:h-full p-4 flex items-center justify-center bg-gray-50 dark:bg-gray-800"><div class="relative w-full max-w-sm h-40 sm:h-48 md:w-84 md:h-60"><img alt="Feature Fusion Deep Reinforcement Learning Approach for Stock Trading" loading="lazy" decoding="async" data-nimg="fill" class="object-contain rounded" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="publications/ccc22bai.png"/></div></div></div><div class="w-full md:w-2/3 p-4 md:p-6"><div class="flex flex-col sm:flex-row sm:items-start sm:justify-between mb-4"><div class="flex-1 mb-2 sm:mb-0"><h3 class="text-lg sm:text-xl font-bold text-gray-900 dark:text-white mb-2">Feature Fusion Deep Reinforcement Learning Approach for Stock Trading</h3><div class="flex items-center gap-2 mb-2 flex-wrap"><p class="text-sm sm:text-base text-gray-600 dark:text-gray-400 whitespace-nowrap"><em>CCC 2022</em></p><span class="px-2 py-0.5 rounded text-xs font-medium bg-slate-200 text-slate-800 dark:bg-slate-700 dark:text-slate-200">EI</span><span class="px-2 py-0.5 rounded text-xs font-medium bg-gray-50 text-gray-500 dark:bg-gray-800/30 dark:text-gray-400">Conference</span><span class="text-sm text-green-600 dark:text-green-400 font-medium">accepted</span></div><p class="text-sm sm:text-base text-gray-700 dark:text-gray-300 mb-2"><span>Tongyuan Bai<!-- -->, </span><span>Qi Lang<!-- -->, </span><span>Shifan Song<!-- -->, </span><span>Yan Fang<!-- -->, </span><span>Xiaodong Liu</span></p></div></div><p class="text-sm sm:text-base text-gray-700 dark:text-gray-300 mb-4 line-clamp-3">This paper presents a novel feature fusion deep reinforcement learning approach for stock trading. The proposed method combines multiple feature extraction techniques with deep reinforcement learning algorithms to improve trading decision-making in financial markets. By integrating various market indicators and technical features, the approach aims to capture complex market dynamics and enhance trading performance through intelligent automated trading strategies.</p><div class="flex flex-wrap gap-2 sm:gap-3"><a href="https://ieeexplore.ieee.org/abstract/document/9901810" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 bg-blue-600 text-white rounded-md hover:bg-blue-700 transition-colors text-sm"><svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 10v6m0 0l-3-3m3 3l3-3m2 8H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg>Paper</a></div></div></div></div></div></div></section><section id="news" class="py-16 px-4 sm:px-6 lg:px-8 bg-gradient-to-br from-amber-50/60 via-yellow-50/40 to-orange-50/30 dark:from-amber-900/20 dark:via-yellow-900/15 dark:to-orange-900/10"><div class="max-w-4xl mx-auto"><div class="text-center mb-12"><h2 class="text-3xl font-bold text-gray-900 dark:text-white mb-4">News</h2><p class="text-lg text-gray-600 dark:text-gray-300">Latest academic updates and research progress</p></div><div class="space-y-6"><div class="
        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 
        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20
        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 
        border-l-4 bg-blue-50 dark:bg-blue-900/20 border-blue-200 dark:border-blue-800 p-6
      "><div class="flex items-start space-x-4"><div class="flex-shrink-0 mt-1"><svg class="w-5 h-5 text-blue-600 dark:text-blue-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 14l9-5-9-5-9 5 9 5z"></path><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 14l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14z"></path></svg></div><div class="flex-1 min-w-0"><div class="flex items-center justify-between mb-2"><h3 class="text-lg font-semibold text-gray-900 dark:text-white">Our paper accepted to CVPR 2025</h3><time class="text-sm text-gray-500 dark:text-gray-400 flex-shrink-0 ml-4">March 20, 2025</time></div><p class="text-gray-700 dark:text-gray-300 mb-3">Our paper &#x27;FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts&#x27; has been accepted to CVPR 2025!</p><a href="#publications" class="inline-flex items-center text-blue-600 dark:text-blue-400 hover:text-blue-700 dark:hover:text-blue-300 text-sm font-medium">Learn More<svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg></a></div></div></div><div class="
        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 
        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20
        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 
        border-l-4 bg-blue-50 dark:bg-blue-900/20 border-blue-200 dark:border-blue-800 p-6
      "><div class="flex items-start space-x-4"><div class="flex-shrink-0 mt-1"><svg class="w-5 h-5 text-blue-600 dark:text-blue-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 14l9-5-9-5-9 5 9 5z"></path><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 14l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14z"></path></svg></div><div class="flex-1 min-w-0"><div class="flex items-center justify-between mb-2"><h3 class="text-lg font-semibold text-gray-900 dark:text-white">Our paper accepted to AAAI 2025</h3><time class="text-sm text-gray-500 dark:text-gray-400 flex-shrink-0 ml-4">December 10, 2024</time></div><p class="text-gray-700 dark:text-gray-300 mb-3">Our paper &#x27;SigStyle: Signature Style Transfer via Personalized Text-to-Image Models&#x27; has been accepted to AAAI 2025!</p><a href="#publications" class="inline-flex items-center text-blue-600 dark:text-blue-400 hover:text-blue-700 dark:hover:text-blue-300 text-sm font-medium">Learn More<svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg></a></div></div></div></div></div></section></main><footer class="bg-gray-900 text-white py-12"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8"><div class="grid grid-cols-1 md:grid-cols-3 gap-8"><div><h3 class="text-lg font-semibold mb-4">Tongyuan Bai</h3><p class="text-gray-300 mb-4">I am a Ph.D. student working at the intersection of artificial intelligence and computer graphics. My current work focuses on generating 3D spatial layouts for indoor and outdoor scene using diffusion models and large language models. My research vision is to automate the creation of diverse 3D scene, particularly those that exist solely in the realm of human imagination, contributing to the development of richly immersive and limitless virtual worlds.</p><div class="flex space-x-4"><a href="https://github.com/cangmushui" target="_blank" rel="noopener noreferrer" class="text-gray-300 hover:text-white transition-colors"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"></path></svg></a><a href="https://linkedin.com/in/Ê∞¥-Êú®-680a48224" target="_blank" rel="noopener noreferrer" class="text-gray-300 hover:text-white transition-colors"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a><a href="https://scholar.google.com/citations?user=NHBB0_4AAAAJ" target="_blank" rel="noopener noreferrer" class="text-gray-300 hover:text-white transition-colors"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"></path></svg></a></div></div><div><h3 class="text-lg font-semibold mb-4">Quick Links</h3><ul class="space-y-2"><li><a href="#about" class="text-gray-300 hover:text-white transition-colors">About Me</a></li><li><a href="#publications" class="text-gray-300 hover:text-white transition-colors">Publications</a></li><li><a href="#news" class="text-gray-300 hover:text-white transition-colors">News</a></li></ul></div><div><h3 class="text-lg font-semibold mb-4">Contact Info</h3><div class="space-y-2 text-gray-300"><p>üìß <!-- -->baity23@mails.jlu.edu.cn</p><p>üìç <!-- -->Changchun, China</p><p>üè¢ <!-- -->Jinlin university</p></div></div></div><div class="mt-8 pt-8 border-t border-gray-700"><div class="flex flex-col md:flex-row justify-between items-center"><p class="text-gray-300 text-sm">¬© <!-- -->2025<!-- --> <!-- -->Tongyuan Bai<!-- -->. All rights reserved.</p><p class="text-gray-300 text-sm mt-2 md:mt-0">Built with Next.js and Tailwind CSS</p></div></div></div></footer></div><!--$--><!--/$--><!--$--><!--/$--><script src="_next/static/chunks/webpack-f24413172d2dbc89.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n4:I[5430,[\"766\",\"static/chunks/766-235bf725b637b196.js\",\"874\",\"static/chunks/874-d2167264e87190e5.js\",\"974\",\"static/chunks/app/page-4b888e98a52f9144.js\"],\"default\"]\n5:I[8431,[\"766\",\"static/chunks/766-235bf725b637b196.js\",\"874\",\"static/chunks/874-d2167264e87190e5.js\",\"974\",\"static/chunks/app/page-4b888e98a52f9144.js\"],\"default\"]\n6:I[3063,[\"766\",\"static/chunks/766-235bf725b637b196.js\",\"874\",\"static/chunks/874-d2167264e87190e5.js\",\"974\",\"static/chunks/app/page-4b888e98a52f9144.js\"],\"Image\"]\n7:I[3946,[\"766\",\"static/chunks/766-235bf725b637b196.js\",\"874\",\"static/chunks/874-d2167264e87190e5.js\",\"974\",\"static/chunks/app/page-4b888e98a52f9144.js\"],\"default\"]\n8:I[14,[\"766\",\"static/chunks/766-235bf725b637b196.js\",\"874\",\"static/chunks/874-d2167264e87190e5.js\",\"974\",\"static/chunks/app/page-4b888e98a52f9144.js\"],\"default\"]\n9:I[9665,[],\"MetadataBoundary\"]\nb:I[9665,[],\"OutletBoundary\"]\ne:I[4911,[],\"AsyncMetadataOutlet\"]\n10:I[9665,[],\"ViewportBoundary\"]\n12:I[6614,[],\"\"]\n:HL[\"/_next/static/css/54e43c5c623f2a4b.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"VpmF1KRP28UXoAjnnTnnp\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/54e43c5c623f2a4b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"font-serif antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-white dark:bg-gray-900\",\"children\":[[\"$\",\"$L4\",null,{}],[\"$\",\"main\",null,{\"children\":[[\"$\",\"$L5\",null,{}],[\"$\",\"section\",null,{\"id\":\"about\",\"className\":\"py-16 px-4 sm:px-6 lg:px-8 bg-gradient-to-br from-amber-50/60 via-yellow-50/40 to-orange-50/30 dark:from-amber-900/20 dark:via-yellow-900/15 dark:to-orange-900/10\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-12\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900 dark:text-white mb-4\",\"children\":\"About Me\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-600 dark:text-gray-300\",\"children\":\"My background and expertise\"}]]}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 lg:grid-cols-3 gap-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"\\n        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 \\n        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20\\n        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 \\n        p-6\\n      \",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-12 h-12 bg-blue-100 dark:bg-blue-900 rounded-lg flex items-center justify-center mx-auto mb-4\",\"children\":[\"$\",\"svg\",null,{\"className\":\"w-6 h-6 text-blue-600 dark:text-blue-400\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\"}]}]}],[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold text-gray-900 dark:text-white mb-4\",\"children\":\"Research Interests\"}]]}],[\"$\",\"div\",null,{\"className\":\"space-y-2\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"flex items-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-2 h-2 bg-blue-500 rounded-full mr-3\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-700 dark:text-gray-300\",\"children\":\"3D Scene Generation\"}]]}],[\"$\",\"div\",\"1\",{\"className\":\"flex items-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-2 h-2 bg-blue-500 rounded-full mr-3\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-700 dark:text-gray-300\",\"children\":\"Computer Graphics\"}]]}],[\"$\",\"div\",\"2\",{\"className\":\"flex items-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-2 h-2 bg-blue-500 rounded-full mr-3\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-700 dark:text-gray-300\",\"children\":\"Diffusion Model\"}]]}],[\"$\",\"div\",\"3\",{\"className\":\"flex items-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-2 h-2 bg-blue-500 rounded-full mr-3\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-700 dark:text-gray-300\",\"children\":\"Large Language Model\"}]]}],[\"$\",\"div\",\"4\",{\"className\":\"flex items-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-2 h-2 bg-blue-500 rounded-full mr-3\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-700 dark:text-gray-300\",\"children\":\"Agent\u0026MCP\"}]]}],[\"$\",\"div\",\"5\",{\"className\":\"flex items-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-2 h-2 bg-blue-500 rounded-full mr-3\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-700 dark:text-gray-300\",\"children\":\"Reinforcement Learning\"}]]}],[\"$\",\"div\",\"6\",{\"className\":\"flex items-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-2 h-2 bg-blue-500 rounded-full mr-3\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-700 dark:text-gray-300\",\"children\":\"Any Technology that Helps Build Interesting Worlds\"}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"\\n        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 \\n        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20\\n        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 \\n        p-6\\n      \",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-12 h-12 bg-green-100 dark:bg-green-900 rounded-lg flex items-center justify-center mx-auto mb-4\",\"children\":[\"$\",\"svg\",null,{\"className\":\"w-6 h-6 text-green-600 dark:text-green-400\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M12 14l9-5-9-5-9 5 9 5z\"}],[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M12 14l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14z\"}],[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M12 14l9-5-9-5-9 5 9 5zm0 0l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14z\"}]]}]}],[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold text-gray-900 dark:text-white mb-4\",\"children\":\"Education\"}]]}],[\"$\",\"div\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"div\",\"edu-0\",{\"className\":\"border-l-2 border-blue-200 dark:border-blue-700 pl-4\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-start space-x-3\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex-shrink-0 mt-1\",\"children\":[\"$\",\"$L6\",null,{\"src\":\"/logos/tju.svg\",\"alt\":\"Tianjin University logo\",\"width\":32,\"height\":32,\"className\":\"w-8 h-8 object-contain rounded\"}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-semibold text-gray-900 dark:text-white\",\"children\":\"Bachelor\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600 dark:text-gray-400\",\"children\":\"Automation\"}],[\"$\",\"p\",null,{\"className\":\"text-sm font-medium text-blue-600 dark:text-blue-400\",\"children\":\"Tianjin University\"}],[\"$\",\"p\",null,{\"className\":\"text-xs text-gray-500 dark:text-gray-500\",\"children\":\"graduated in 2018\"}]]}]]}]}],[\"$\",\"div\",\"edu-1\",{\"className\":\"border-l-2 border-blue-200 dark:border-blue-700 pl-4\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-start space-x-3\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex-shrink-0 mt-1\",\"children\":[\"$\",\"$L6\",null,{\"src\":\"/logos/dlut.svg\",\"alt\":\"Dalian University of Technology logo\",\"width\":32,\"height\":32,\"className\":\"w-8 h-8 object-contain rounded\"}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-semibold text-gray-900 dark:text-white\",\"children\":\"Master\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600 dark:text-gray-400\",\"children\":\"Control Engineering\"}],[\"$\",\"p\",null,{\"className\":\"text-sm font-medium text-blue-600 dark:text-blue-400\",\"children\":\"Dalian University of Technology\"}],[\"$\",\"p\",null,{\"className\":\"text-xs text-gray-500 dark:text-gray-500\",\"children\":\"2020 - 2023\"}]]}]]}]}],[\"$\",\"div\",\"edu-2\",{\"className\":\"border-l-2 border-blue-200 dark:border-blue-700 pl-4\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-start space-x-3\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex-shrink-0 mt-1\",\"children\":[\"$\",\"$L6\",null,{\"src\":\"/logos/jlu.svg\",\"alt\":\"Jilin University logo\",\"width\":32,\"height\":32,\"className\":\"w-8 h-8 object-contain rounded\"}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-semibold text-gray-900 dark:text-white\",\"children\":\"Ph.D. Candidate\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600 dark:text-gray-400\",\"children\":\"Artificial Intelligence\"}],[\"$\",\"p\",null,{\"className\":\"text-sm font-medium text-blue-600 dark:text-blue-400\",\"children\":\"Jilin University\"}],[\"$\",\"p\",null,{\"className\":\"text-xs text-gray-500 dark:text-gray-500\",\"children\":\"2023 - Present\"}]]}]]}]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"\\n        bg-white/80 backdrop-blur-sm dark:bg-gray-800/90 \\n        rounded-lg shadow-md border border-amber-100/50 dark:border-amber-900/20\\n        hover:shadow-lg hover:shadow-amber-200/20 dark:hover:shadow-amber-900/30 transition-all duration-200 \\n        p-6\\n      \",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-12 h-12 bg-purple-100 dark:bg-purple-900 rounded-lg flex items-center justify-center mx-auto mb-4\",\"children\":[\"$\",\"svg\",null,{\"className\":\"w-6 h-6 text-purple-600 dark:text-purple-400\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M21 13.255A23.931 23.931 0 0112 15c-3.183 0-6.22-.62-9-1.745M16 6V4a2 2 0 00-2-2h-4a2 2 0 00-2-2v2m8 0V6a2 2 0 012 2v6a2 2 0 01-2 2H6a2 2 0 01-2-2V8a2 2 0 012-2V6m8 0H8m0 0h-.01M8 6h.01M8 10h.01M8 10h.01M8 14h.01M8 14h.01\"}]}]}],[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold text-gray-900 dark:text-white mb-4\",\"children\":\"Work Experience\"}]]}],[\"$\",\"div\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"div\",\"exp-0\",{\"className\":\"border-l-2 border-purple-200 dark:border-purple-700 pl-4\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-semibold text-gray-900 dark:text-white\",\"children\":\"FPGA Radar Engineer\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600 dark:text-gray-400\",\"children\":\"Worked on FPGA-based radar systems development and signal processing.\"}],[\"$\",\"p\",null,{\"className\":\"text-sm font-medium text-purple-600 dark:text-purple-400\",\"children\":\"Leijiu Technology Co., Ltd.\"}],[\"$\",\"p\",null,{\"className\":\"text-xs text-gray-500 dark:text-gray-500\",\"children\":\"2018 - 2019\"}]]}],[\"$\",\"div\",\"exp-1\",{\"className\":\"border-l-2 border-purple-200 dark:border-purple-700 pl-4\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-semibold text-gray-900 dark:text-white\",\"children\":\"Backend Engineer(Intern)\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600 dark:text-gray-400\",\"children\":\"Worked as a backend engineer intern in the Overseas Recommendation System team, responsible for backend development.\"}],[\"$\",\"p\",null,{\"className\":\"text-sm font-medium text-purple-600 dark:text-purple-400\",\"children\":\"ByteDance-Data-AML\"}],[\"$\",\"p\",null,{\"className\":\"text-xs text-gray-500 dark:text-gray-500\",\"children\":\"2022.6 - 2022.9\"}]]}]]}]]}]]}]]}]}],[\"$\",\"$L7\",null,{}],[\"$\",\"$L8\",null,{}]]}],[\"$\",\"footer\",null,{\"className\":\"bg-gray-900 text-white py-12\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto px-4 sm:px-6 lg:px-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-3 gap-8\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg font-semibold mb-4\",\"children\":\"Tongyuan Bai\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-300 mb-4\",\"children\":\"I am a Ph.D. student working at the intersection of artificial intelligence and computer graphics. My current work focuses on generating 3D spatial layouts for indoor and outdoor scene using diffusion models and large language models. My research vision is to automate the creation of diverse 3D scene, particularly those that exist solely in the realm of human imagination, contributing to the development of richly immersive and limitless virtual worlds.\"}],[\"$\",\"div\",null,{\"className\":\"flex space-x-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://github.com/cangmushui\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-gray-300 hover:text-white transition-colors\",\"children\":[\"$\",\"svg\",null,{\"className\":\"w-5 h-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"d\":\"M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z\"}]}]}],[\"$\",\"a\",null,{\"href\":\"https://linkedin.com/in/Ê∞¥-Êú®-680a48224\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-gray-300 hover:text-white transition-colors\",\"children\":[\"$\",\"svg\",null,{\"className\":\"w-5 h-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"d\":\"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z\"}]}]}],[\"$\",\"a\",null,{\"href\":\"https://scholar.google.com/citations?user=NHBB0_4AAAAJ\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-gray-300 hover:text-white transition-colors\",\"children\":[\"$\",\"svg\",null,{\"className\":\"w-5 h-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"d\":\"M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z\"}]}]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg font-semibold mb-4\",\"children\":\"Quick Links\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-2\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"#about\",\"className\":\"text-gray-300 hover:text-white transition-colors\",\"children\":\"About Me\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"#publications\",\"className\":\"text-gray-300 hover:text-white transition-colors\",\"children\":\"Publications\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"#news\",\"className\":\"text-gray-300 hover:text-white transition-colors\",\"children\":\"News\"}]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg font-semibold mb-4\",\"children\":\"Contact Info\"}],[\"$\",\"div\",null,{\"className\":\"space-y-2 text-gray-300\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"üìß \",\"baity23@mails.jlu.edu.cn\"]}],[\"$\",\"p\",null,{\"children\":[\"üìç \",\"Changchun, China\"]}],[\"$\",\"p\",null,{\"children\":[\"üè¢ \",\"Jinlin university\"]}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 pt-8 border-t border-gray-700\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col md:flex-row justify-between items-center\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-gray-300 text-sm\",\"children\":[\"¬© \",2025,\" \",\"Tongyuan Bai\",\". All rights reserved.\"]}],[\"$\",\"p\",null,{\"className\":\"text-gray-300 text-sm mt-2 md:mt-0\",\"children\":\"Built with Next.js and Tailwind CSS\"}]]}]}]]}]}]]}],[\"$\",\"$L9\",null,{\"children\":\"$La\"}],null,[\"$\",\"$Lb\",null,{\"children\":[\"$Lc\",\"$Ld\",[\"$\",\"$Le\",null,{\"promise\":\"$@f\"}]]}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"JpmRg7ujAZKoeGJU7GqUm\",{\"children\":[[\"$\",\"$L10\",null,{\"children\":\"$L11\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$12\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"13:\"$Sreact.suspense\"\n14:I[4911,[],\"AsyncMetadata\"]\na:[\"$\",\"$13\",null,{\"fallback\":null,\"children\":[\"$\",\"$L14\",null,{\"promise\":\"$@15\"}]}]\n"])</script><script>self.__next_f.push([1,"d:null\n"])</script><script>self.__next_f.push([1,"11:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nc:null\n"])</script><script>self.__next_f.push([1,"15:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Tongyuan Bai - Academic Portfolio\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"AI researcher specializing in 3D scene generation, video generation, and diffusion models. Sharing latest research achievements and academic insights.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Tongyuan Bai\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"artificial intelligence,machine learning,deep learning,3D scene generation,diffusion models,computer vision\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Tongyuan Bai\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Tongyuan Bai\"}],[\"$\",\"meta\",\"6\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:title\",\"content\":\"Tongyuan Bai - Academic Portfolio\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:description\",\"content\":\"AI researcher specializing in 3D scene generation, video generation, and diffusion models.\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:url\",\"content\":\"https://cangmushui.github.io/\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:site_name\",\"content\":\"Tongyuan Bai's Academic Portfolio\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:image\",\"content\":\"https://cangmushui.github.io/avatar.jpg\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:image:width\",\"content\":\"400\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:image:height\",\"content\":\"400\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image:alt\",\"content\":\"Tongyuan Bai\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:creator\",\"content\":\"@cangmushui\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:title\",\"content\":\"Tongyuan Bai - Academic Portfolio\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:description\",\"content\":\"AI researcher specializing in 3D scene generation and diffusion models\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:image\",\"content\":\"https://cangmushui.github.io/avatar.jpg\"}],[\"$\",\"link\",\"22\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"f:{\"metadata\":\"$15:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>